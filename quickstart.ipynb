{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd235fb0",
   "metadata": {},
   "source": [
    "# Bias Buccaneers Image Recognition Challenge: Quickstart\n",
    "\n",
    "This notebook will introduce you to the data and describe a workflow to train and evaluate a baseline model on it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad57b0b7",
   "metadata": {},
   "source": [
    "## Initial Setup\n",
    "\n",
    "We start with loading the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2454f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fd2d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536f1fd6",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "Make sure to download and uncompress the data (`data_bb1_img_recognition.zip`) in the folder you're working off of.\n",
    "\n",
    "We first load the file containing the labels, binarize labels of each of the three classes as a numpy array and store them as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c742f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "LOADPATH = './data_bb1_img_recognition/train/'\n",
    "SAVEPATH = './data_bb1_img_recognition/models/'\n",
    "df = pd.read_csv(LOADPATH+'labels.csv')\n",
    "df_labeled = df[df[\"skin_tone\"].notna()] # take only labeled data\n",
    "\n",
    "# Converting labels to np array\n",
    "cat = ['skin_tone','gender','age']\n",
    "lbs = [LabelBinarizer() for i in range(3)]\n",
    "Y = []\n",
    "for i in range(3):\n",
    "    lab = lbs[i].fit_transform(df_labeled[cat[i]])\n",
    "    if lab.shape[1]==1:\n",
    "        Y.append(np.hstack((1-lab,lab)))\n",
    "    else:\n",
    "        Y.append(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f982a45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8553, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4277c378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       ...,\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb73277",
   "metadata": {},
   "source": [
    "We then load the images under the training set and convert them to numpy arrays. This may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f957a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m length \u001b[39m=\u001b[39m width \u001b[39m=\u001b[39m \u001b[39m64\u001b[39m \u001b[39m# size for each input image, increase if you want\u001b[39;00m\n\u001b[1;32m      4\u001b[0m nn \u001b[39m=\u001b[39m df_labeled\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m all_imgs \u001b[39m=\u001b[39m [image\u001b[39m.\u001b[39mload_img(LOADPATH\u001b[39m+\u001b[39mdf_labeled\u001b[39m.\u001b[39miloc[i][\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m], target_size\u001b[39m=\u001b[39m(length,width)) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(nn)]\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mConverting images to np array\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty([nn, length, width, \u001b[39m3\u001b[39m], dtype\u001b[39m=\u001b[39m\u001b[39mfloat\u001b[39m)\n",
      "Cell \u001b[0;32mIn [18], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m length \u001b[39m=\u001b[39m width \u001b[39m=\u001b[39m \u001b[39m64\u001b[39m \u001b[39m# size for each input image, increase if you want\u001b[39;00m\n\u001b[1;32m      4\u001b[0m nn \u001b[39m=\u001b[39m df_labeled\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m all_imgs \u001b[39m=\u001b[39m [image\u001b[39m.\u001b[39mload_img(LOADPATH\u001b[39m+\u001b[39mdf_labeled\u001b[39m.\u001b[39miloc[i][\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m], target_size\u001b[39m=\u001b[39m(length,width)) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(nn)]\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mConverting images to np array\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty([nn, length, width, \u001b[39m3\u001b[39m], dtype\u001b[39m=\u001b[39m\u001b[39mfloat\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "# loading and converting data into np array\n",
    "print(\"Loading images\")\n",
    "length = width = 64 # size for each input image, increase if you want\n",
    "nn = df_labeled.shape[0]\n",
    "all_imgs = [image.load_img(LOADPATH+df_labeled.iloc[i]['name'], target_size=(length,width)) for i in range(nn)]\n",
    "\n",
    "print(\"Converting images to np array\")\n",
    "X = np.empty([nn, length, width, 3], dtype=float)\n",
    "for i in range(nn):\n",
    "    X[i,:] = image.img_to_array(all_imgs[i])\n",
    "X = K.applications.resnet50.preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1610c108",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_imgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_imgs[\u001b[39m1234\u001b[39m] \u001b[39m# print a test image\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_imgs' is not defined"
     ]
    }
   ],
   "source": [
    "all_imgs[1234] # print a test image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf14ba8",
   "metadata": {},
   "source": [
    "## Specify the Model\n",
    "\n",
    "We define a single model class that is able train on the data in `X` and `Y` and predict outcomes for all three classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40c55abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionModel():\n",
    "    def __init__(self, X, Y, idx):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.idx = idx\n",
    "        self.trainX, self.testX = X[idx[0],:], X[idx[1],:]\n",
    "        self.trainY, self.testY = [Y[i][idx[0],:] for i in range(3)], [Y[i][idx[1],:] for i in range(3)]\n",
    "        self.cat = ['skin_tone','gender','age']\n",
    "        self.loss = ['categorical_crossentropy' for i in range(3)]\n",
    "        self.metrics = [['accuracy'] for i in range(3)]\n",
    "        self.models = [None]*3\n",
    "\n",
    "    # train a model specific for a certain class index in self.cat\n",
    "    def fit(self, index, model, epochs=5, batch_size=32, save=False, save_location=None, verbose=1):\n",
    "        \n",
    "        if verbose: print(\"Training model for \"+self.cat[index])\n",
    "        model.add(K.layers.Dense(self.trainY[index].shape[1], activation='softmax'))\n",
    "        model.compile(loss=self.loss[index], optimizer='Adam', metrics=self.metrics[index])\n",
    "        model.fit(\n",
    "            self.trainX, self.trainY[index], \n",
    "            validation_data=(self.testX,self.testY[index]), \n",
    "            batch_size=batch_size, epochs=epochs, verbose=verbose\n",
    "        )\n",
    "        if save:\n",
    "            if os.path.exists(SAVEPATH)==False:\n",
    "                print('save location '+SAVEPATH+' did not exist. creating')\n",
    "                os.makedirs(SAVEPATH)\n",
    "            SAVE_LOCATION = save_location+'model_'+cat[index]+'.h5'\n",
    "            print(\"saving model at \"+SAVE_LOCATION)\n",
    "            model.save(SAVE_LOCATION)\n",
    "        self.models[index] = model\n",
    "            \n",
    "    def predict(self, newX):\n",
    "        predictions = [model.predict(newX) for model in self.models]\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76ae9ef",
   "metadata": {},
   "source": [
    "## Initialize and Train a Model\n",
    "\n",
    "We now train a `PredictionModel` to predict the likely skin tone, gender, and age of an input image. This baseline model is initialize on imagenet weights and uses the ResNet50 architecture. We strongly recommend using a GPU to reduce training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da29fedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for skin_tone\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 16s 85ms/step - loss: 2.6600 - accuracy: 0.1320 - val_loss: 4.7888 - val_accuracy: 0.1360\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 14s 77ms/step - loss: 2.3338 - accuracy: 0.1710 - val_loss: 2.1001 - val_accuracy: 0.2062\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 15s 77ms/step - loss: 2.1921 - accuracy: 0.1862 - val_loss: 2.0502 - val_accuracy: 0.2241\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 15s 77ms/step - loss: 2.0914 - accuracy: 0.2009 - val_loss: 1.9529 - val_accuracy: 0.2249\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 14s 77ms/step - loss: 2.0117 - accuracy: 0.2220 - val_loss: 1.9467 - val_accuracy: 0.2284\n",
      "save location ./models/ did not exist. creating\n",
      "saving model at ./models/model_skin_tone.h5\n",
      "Training model for gender\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 16s 85ms/step - loss: 0.7269 - accuracy: 0.6130 - val_loss: 0.6789 - val_accuracy: 0.7330\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 14s 77ms/step - loss: 0.5473 - accuracy: 0.7099 - val_loss: 0.4999 - val_accuracy: 0.7432\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 14s 77ms/step - loss: 0.4957 - accuracy: 0.7419 - val_loss: 0.5029 - val_accuracy: 0.7553\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 14s 77ms/step - loss: 0.4427 - accuracy: 0.7718 - val_loss: 0.4637 - val_accuracy: 0.7681\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 15s 77ms/step - loss: 0.4198 - accuracy: 0.7885 - val_loss: 0.5197 - val_accuracy: 0.7736\n",
      "saving model at ./models/model_gender.h5\n",
      "Training model for age\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 16s 85ms/step - loss: 1.4974 - accuracy: 0.3663 - val_loss: 1.3282 - val_accuracy: 0.5413\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 15s 79ms/step - loss: 1.2276 - accuracy: 0.4732 - val_loss: 1.0369 - val_accuracy: 0.5401\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 14s 77ms/step - loss: 1.1098 - accuracy: 0.5155 - val_loss: 0.9914 - val_accuracy: 0.5577\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 15s 78ms/step - loss: 1.0553 - accuracy: 0.5469 - val_loss: 0.9747 - val_accuracy: 0.5705\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 15s 78ms/step - loss: 0.9993 - accuracy: 0.5727 - val_loss: 0.9679 - val_accuracy: 0.5752\n",
      "saving model at ./models/model_age.h5\n"
     ]
    }
   ],
   "source": [
    "# function to initialize a model\n",
    "def initializeModel():\n",
    "    res_model = ResNet50(include_top=False, weights='imagenet', input_tensor=K.Input(shape=[length,width,3]))\n",
    "\n",
    "    # freeze all but the last layer\n",
    "    for layer in res_model.layers[:143]:\n",
    "        layer.trainable = False\n",
    "    model = K.models.Sequential()\n",
    "    model.add(res_model)\n",
    "    model.add(K.layers.Flatten())\n",
    "    model.add(K.layers.BatchNormalization())\n",
    "    model.add(K.layers.Dense(256, activation='relu'))\n",
    "    model.add(K.layers.Dropout(0.5))\n",
    "    model.add(K.layers.BatchNormalization())\n",
    "    model.add(K.layers.Dense(128, activation='relu'))\n",
    "    model.add(K.layers.Dropout(0.5))\n",
    "    model.add(K.layers.BatchNormalization())\n",
    "    model.add(K.layers.Dense(64, activation='relu'))\n",
    "    model.add(K.layers.Dropout(0.5))\n",
    "    model.add(K.layers.BatchNormalization())\n",
    "    return model\n",
    "\n",
    "nntrain = int(0.7*nn)\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(nn)\n",
    "train_idx, test_idx = indices[:nntrain], indices[nntrain:]\n",
    "mymodel = PredictionModel(X=X, Y=Y, idx=[train_idx,test_idx])\n",
    "\n",
    "# train model\n",
    "for i in range(3):\n",
    "    mymodel.fit(index=i, model=initializeModel(), epochs=5, save=True, save_location=SAVEPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6527b5ae",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "\n",
    "We now evaluate the model on the test data. To do this, let's first load up that data and structure it similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43ab27c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting test labels to np array\n",
      "Loading test images\n",
      "Converting test images to np array\n"
     ]
    }
   ],
   "source": [
    "# load labels data\n",
    "TESTPATH = './test/'\n",
    "df_test = pd.read_csv(TESTPATH+'labels.csv')\n",
    "\n",
    "# Convert labels to np array\n",
    "print(\"Converting test labels to np array\")\n",
    "testY = []\n",
    "for i in range(3):\n",
    "    lab = lbs[i].fit_transform(df_test[cat[i]])\n",
    "    if lab.shape[1]==1:\n",
    "        testY.append(np.hstack((1-lab,lab)))\n",
    "    else:\n",
    "        testY.append(lab)\n",
    "        \n",
    "# load and convert images into np array\n",
    "print(\"Loading test images\")\n",
    "nt = df_test.shape[0]\n",
    "all_imgs = [image.load_img(TESTPATH+df_test.iloc[i]['name'], target_size=(length,width)) for i in range(nt)]\n",
    "\n",
    "print(\"Converting test images to np array\")\n",
    "testX = np.empty([nt, length, width, 3], dtype=float)\n",
    "for i in range(nt):\n",
    "    testX[i,:] = image.img_to_array(all_imgs[i])\n",
    "testX = K.applications.resnet50.preprocess_input(testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07ee94e",
   "metadata": {},
   "source": [
    "We then obtain predicted labels for skin tone, gender, and age as a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf106302",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = mymodel.predict(testX)\n",
    "predY = [[np.argmax(pred[i][j,:]) for j in range(nt)] for i in range(3)]\n",
    "predLabels = [[lbs[i].classes_[j] for j in predY[i]] for i in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0cf73d",
   "metadata": {},
   "source": [
    "Finally, we calculate the label-wise accuracy and disparity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "081d5cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': {'skin_tone': 0.25766666666666665,\n",
       "  'gender': 0.7966666666666666,\n",
       "  'age': 0.5783333333333334},\n",
       " 'disparity': {'skin_tone': 0.5514223194748359,\n",
       "  'gender': 0.1493182689960596,\n",
       "  'age': 0.7802908824936}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "acc = {}\n",
    "for i in range(3):\n",
    "    icat = cat[i]\n",
    "    iacc = accuracy_score(df_test[cat[i]], predLabels[i])\n",
    "    acc[icat] = iacc\n",
    "\n",
    "# calculate disparity\n",
    "def disparity_score(ytrue, ypred):\n",
    "    cm = confusion_matrix(ytrue,ypred)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    all_acc = list(cm.diagonal())\n",
    "    return max(all_acc) - min(all_acc)\n",
    "\n",
    "disp = {}\n",
    "for i in range(3):\n",
    "    icat = cat[i]\n",
    "    idisp = disparity_score(df_test[cat[i]], predLabels[i])\n",
    "    disp[icat] = idisp\n",
    "disp\n",
    "\n",
    "results = {'accuracy': acc, 'disparity': disp}\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20b0fcd",
   "metadata": {},
   "source": [
    "# Score Model and Prepare Submission\n",
    "\n",
    "Based on the above metric, we now calculate the score to evaluate your submission. This score will be displayed in your public leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "db5b9086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'submission_name': '8-Bit Bias Bounty Baseline',\n",
       " 'score': 4.705572543130653,\n",
       " 'metrics': {'accuracy': {'skin_tone': 0.25766666666666665,\n",
       "   'gender': 0.7966666666666666,\n",
       "   'age': 0.5783333333333334},\n",
       "  'disparity': {'skin_tone': 0.5514223194748359,\n",
       "   'gender': 0.1493182689960596,\n",
       "   'age': 0.7802908824936}}}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getScore(results):\n",
    "    acc = results['accuracy']\n",
    "    disp = results['disparity']\n",
    "    ad = 2*acc['gender']*(1-disp['gender']) + 4*acc['age']*(1-disp['age']**2) + 10*acc['skin_tone']*(1-disp['skin_tone']**5)\n",
    "    return ad\n",
    "\n",
    "title = '8-Bit Bias Bounty Baseline'\n",
    "    \n",
    "submission = {\n",
    "    'submission_name': title,\n",
    "    'score': getScore(results),\n",
    "    'metrics': results\n",
    "}\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19070a4e",
   "metadata": {},
   "source": [
    "Finally, let's export this as a json file to upload as part of filling out your [submission form](https://docs.google.com/forms/d/e/1FAIpQLSfwqtVkJBVRP6TnFp7vHbbH8SlwKZJFIjvGQy7TyYFc8HR1hw/viewform)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34c30e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"baseline_score.json\", \"w\") as f:\n",
    "    json.dump(submission, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('bb1-img-recognition-UPNUlOZL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "1910b6696973d15bf216d34a2b579ebfef615f9fbc990caf22091bbcd689422a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
